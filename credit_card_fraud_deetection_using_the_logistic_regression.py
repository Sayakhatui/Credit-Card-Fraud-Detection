# -*- coding: utf-8 -*-
"""Credit card fraud deetection using the Logistic regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1df1_0mTZlkj75FXaWQX_yIyV_LCkqwvH
"""




"""importing the dependencies"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

#loading the dataset in the Pandas DataFrame
credit_card_data=pd.read_csv(r'D:\5th sem\daa\project\creditcard.csv')


#first 5 rows of the dataset
credit_card_data.head()

#checking the last five rows of the dataframe
credit_card_data.tail()

#dataset information
credit_card_data.info()

#checking the number of the missing values in each column
credit_card_data.isnull().sum()

"""from the above output we have  no missing values

"""

#distribution of the legit transaction & fradulent transactions
credit_card_data['Class'].value_counts()

"""This is a highly unbalanced dataset
as seen by the histograms containing ouliners that affect the overall acurracy of the data set

"""

credit_card_data.hist(bins=30, figsize=(30, 30))

#dataset information
credit_card_data.info()

"""


1.  0 --->> Normal transaction
2.  1--->> fradulent transaction

"""

#seperating the data for the analysis
legit =credit_card_data[credit_card_data.Class==0]
fraud =credit_card_data[credit_card_data.Class==1]

print(legit.shape)
print(fraud.shape)

#statistical measures of the data
legit.Amount.describe()

"""From the summary statistics provided for the "Amount" column in the credit card fraud dataset, we can gather several insights and information about the data:

Data Distribution:** You can see that the "Amount" data is right-skewed, as the mean (average) is greater than the median (50th percentile). This suggests that there are some transactions with high amounts that are pulling the mean upward.**

Typical Transaction Amount: The median value ($22.00) can be considered the typical or middle transaction amount. It indicates that half of the transactions have an amount of $22.00 or less.

Variability: The standard deviation ($250.11) is relatively large compared to the mean. This indicates a wide variation in transaction amounts, with some transactions having very high values compared to the majority of transactions.

Outliers: The "max" value of $25,691.16 suggests that there are extreme outliers in the data, representing very high transaction amounts. These outliers could be indicative of potential fraudulent transactions or unusual activity.
**bold text**

**Potential Fraud Detection: The presence of extremely high values (outliers) could be a signal for further investigation, as it may indicate potentially fraudulent transactions. Fraudulent activities often involve larger transaction amounts.**

Imbalanced Data: Depending on the nature of the dataset, the summary statistics may indicate class imbalance, where most transactions are non-fraudulent, and a small percentage are fraudulent. This can impact the training and evaluation of fraud detection models.

These summary statistics are an initial step in understanding the characteristics of the "Amount" data in a credit card fraud dataset. Further analysis and modeling are typically required to detect and address fraudulent transactions effectively.
"""

fraud.Amount.describe()

#compare the values for the both transaction\
credit_card_data.groupby('Class').mean()

"""**Comparison of Legitimate and Fraudulent Transactions:**

Legitimate transactions significantly outnumber fraudulent transactions (284,315 vs. 492), which is expected, as fraud is a relatively rare event.
The mean transaction amount for legitimate transactions is lower ($88.29) compared to fraudulent transactions ($122.21), indicating that, on average, fraudulent transactions have a slightly higher amount.

Under-sampling

Build a sample dataset contaning similar distribution of the normal transaction and Fradulent transaction

Number of the fradulent transaction -->>492

The process we  are describing involves creating a balanced dataset for training a machine learning model by under-sampling the majority class (legitimate transactions) to match the number of samples in the minority class (fraudulent transactions). Here's how this approach can be beneficial:

**Addressing Class Imbalance:** In many real-world datasets, including credit card fraud detection, one class (legitimate transactions) significantly outnumbers the other class (fraudulent transactions). Class imbalance can lead to a biased model that performs poorly on the minority class. By under-sampling the majority class to match the number of samples in the minority class (492 in this case), you create a balanced dataset.

**Model Training:** Balanced datasets provide the machine learning model with an equal opportunity to learn from both classes. This helps prevent the model from being overly biased toward the majority class and increases its ability to detect the minority class (fraudulent transactions) effectively.

**Improved Performance Metrics:** When evaluating the model's performance on a balanced dataset, you get a more accurate representation of how well it can detect both legitimate and fraudulent transactions. This leads to more meaningful performance metrics such as precision, recall, F1-score, and ROC AUC, which are essential for assessing the model's effectiveness in real-world scenarios.

**Reduced Overfitting:** Balancing the dataset can help mitigate overfitting, as the model is less likely to learn to predict the majority class exclusively. This often results in a more generalized model.
"""

legit_sample=legit.sample(n=492)



"""concatenating the two datasets
this is done such the dataset can be used to train the ml model
"""

new_dataset=pd.concat([legit_sample ,fraud],axis=0)

new_dataset.head()

new_dataset.tail()

new_dataset['Class'].value_counts()

credit_card_data.groupby('Class').mean()

"""Splitting the features and targets"""

X=new_dataset.drop(columns='Class',axis=1)
Y=new_dataset['Class']

print(X)

print(Y)

#split data into the training data & testing data

# Split the data into training and testing sets (e.g., 80% for training, 20% for testing)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Optional: We can specify a random_state for reproducibility.
# The test_size parameter determines the proportion of data to allocate for testing.

print(X.shape,X_train.shape,X_test.shape)



"""Model Training

Logistic Regression
"""

model=LogisticRegression()

#trainig the Logistic Regression Model with the training Data
model.fit(X_train, Y_train )

"""Model Evaluation

Accuracy score
"""

from sklearn.metrics import accuracy_score

# Assuming you have trained your machine learning model and made predictions
# Replace `model` with the name of your trained model
Y_train_pred = model.predict(X_train)
Y_test_pred = model.predict(X_test)

# Calculate accuracy on the training data
train_accuracy = accuracy_score(Y_train, Y_train_pred)

# Calculate accuracy on the test data
test_accuracy = accuracy_score(Y_test, Y_test_pred)

print("Training Accuracy:", train_accuracy)
print("Testing Accuracy:", test_accuracy)



